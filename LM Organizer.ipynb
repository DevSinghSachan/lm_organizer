{
 "metadata": {
  "name": "",
  "signature": "sha256:133a00fb78432af8ee4ef17856a2d994692f77159a8ac142a41225dbb43d1a0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Language Model Organizer\n",
      "\n",
      "Language model built around the idea of **binary search**. Method is simple, take any input text, assign a tree to the text by recursively cutting it in halves. Take random words inside and train the vector to separate the words into the tree (hierarchical softmax in a minimalistic setting)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "%config InlineBackend.figure_format = 'svg'\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt, os, numpy as np, time\n",
      "from model import OrganizerModel, BiasOrganizerModel\n",
      "from IPython.display import clear_output\n",
      "from model.utils import DocumentTree, code_to_index, number_of_branches_per_depth, codes_for_depth, codes_upto_depth\n",
      "from model.utils import import_mini_wiki_corpus, collect_counts, save_object, load_object"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "collect words and documents using hash table:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = import_mini_wiki_corpus(\"/users/jonathanraiman/desktop/plaintext_articles/\")\n",
      "if os.path.exists(\"saves/vocab.gz\"):\n",
      "    vocab = load_object(\"saves/vocab.gz\")\n",
      "else:\n",
      "    vocab = collect_counts(corpus)\n",
      "    save_object(vocab, \"saves/vocab.gz\")\n",
      "\n",
      "# convert words:\n",
      "NUM_WORDS = 50000\n",
      "index2word = [word[0] for word in vocab.most_common(NUM_WORDS)]\n",
      "word2index = {}\n",
      "for i, word in enumerate(index2word):\n",
      "    word2index[word] = i\n",
      "   \n",
      "# convert documents:\n",
      "index2document = []\n",
      "document2index = {}\n",
      "if os.path.exists(\"saves/documents.gz\"):\n",
      "    documents = load_object(\"saves/documents.gz\")\n",
      "    index2document = []\n",
      "    document2index = {}\n",
      "    for document in documents:\n",
      "        document2index[document.name]= document.index\n",
      "        index2document.append(document.name)\n",
      "else:\n",
      "    document_index = 0\n",
      "    documents = []\n",
      "    for key, value in corpus.items():\n",
      "        index2document.append(key)\n",
      "        document2index[key] = document_index\n",
      "        documents.append(DocumentTree(key, value, word2index, document_index))\n",
      "        document_index+=1\n",
      "    save_object(documents, \"saves/documents.gz\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "build model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "organizer_model = OrganizerModel(size = 50,\n",
      "                                 tree_depth = 2,\n",
      "                                 learning_rate = 1.0,\n",
      "                                vocabulary_size = NUM_WORDS,\n",
      "                                document_size = len(documents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "organizer_model = BiasOrganizerModel(size = 50,\n",
      "                                     sum_words = True,\n",
      "                                 tree_depth = 2,\n",
      "                                 learning_rate = 0.035,\n",
      "                                vocabulary_size = NUM_WORDS,\n",
      "                                document_size = len(documents))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "okay\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs = 50\n",
      "epoch_cost = 0.0\n",
      "SAMPLE_SIZE = 10\n",
      "# label with 0 for top section\n",
      "# 1 for bottom section of code:\n",
      "SAMPLE_LABELINGS = np.concatenate([np.zeros(SAMPLE_SIZE, dtype=np.int32), np.ones(SAMPLE_SIZE, dtype=np.int32)])\n",
      "\n",
      "codes = [(code, code_to_index(organizer_model.tree_depth,\n",
      "                              code)) for code in codes_upto_depth(organizer_model.tree_depth)]\n",
      "DOCSET = documents[0:100]\n",
      "\n",
      "WINDOWS = 10\n",
      "\n",
      "TOTAL_DOCS = len(DOCSET) / 100.\n",
      "megaerrors = []\n",
      "for epoch in range(epochs):\n",
      "    t1 = time.time()\n",
      "    epoch_cost = 0.0\n",
      "    for k, doc in enumerate(DOCSET):\n",
      "        # for each code (including the null code, parent node)\n",
      "        # we train the vectors using the same words:\n",
      "        for code, branch_offset in codes:\n",
      "            \n",
      "            # Sample top, then bottom word indices from document:\n",
      "            if organizer_model.sum_words:\n",
      "                for window in range(WINDOWS):\n",
      "                    epoch_cost += organizer_model.update_fun(\n",
      "                        doc.create_example(code, top = True, sample_size = SAMPLE_SIZE),\n",
      "                        doc.index,\n",
      "                        branch_offset,\n",
      "                        [0])\n",
      "                    epoch_cost += organizer_model.update_fun(\n",
      "                        doc.create_example(code, top = False, sample_size = SAMPLE_SIZE),\n",
      "                        doc.index,\n",
      "                        branch_offset, [1])\n",
      "                \n",
      "            else:\n",
      "                sample = np.concatenate([\n",
      "                    doc.create_example(code, top = True, sample_size = SAMPLE_SIZE),\n",
      "                    doc.create_example(code, top = False, sample_size = SAMPLE_SIZE)\n",
      "                    ])\n",
      "\n",
      "                # train on them:\n",
      "                epoch_cost += organizer_model.update_fun(sample, doc.index, branch_offset, SAMPLE_LABELINGS)\n",
      "        \n",
      "        if k % 10 == 0:\n",
      "            clear_output(wait=True)\n",
      "            print(\"epoch: %d, progress: %.1f%%, %.2f docs/s, cost: %.2f\" % (epoch, k/TOTAL_DOCS, k / (time.time() - t1), epoch_cost))\n",
      "    megaerrors.append(epoch_cost)\n",
      "    organizer_model.reset_adagrad()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "epoch: 5, progress: 20.0%, 1.26 docs/s, cost: 2038.74\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-39-82819ad2a3b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                         \u001b[0mbranch_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                         [0])\n\u001b[0m\u001b[1;32m     32\u001b[0m                     epoch_cost += organizer_model.update_fun(\n\u001b[1;32m     33\u001b[0m                         \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSAMPLE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.4/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.4/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "organizer_model.theano_mode = 'FAST_COMPILE'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc.create_example(code, top = True, sample_size = 5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([ 5209,     9,     1,   360, 10392], dtype=int32)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "megaerrors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "[9705.3659979701042,\n",
        " 9706.0506512522697,\n",
        " 9706.049772977829,\n",
        " 9706.0187233686447,\n",
        " 9705.9698587656021]"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Inspect results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def most_similar_word(matrix, index2label, label2index, word, topn = 10):\n",
      "        index = label2index[word]\n",
      "        word = matrix[index]\n",
      "        dists = np.dot(matrix, word).astype(np.float32)\n",
      "        best = np.argsort(dists)[::-1][:topn + 1]\n",
      "        result = [(index2label[sim], float(dists[sim]), sim) for sim in best if sim != index]\n",
      "        return result[:topn]\n",
      "def most_similar_doc(matrix, index2label, label2index, word, topn = 10, code = []):\n",
      "        #branch_index = code_to_index(organizer_model.tree_depth, code)\n",
      "        index = label2index[word]\n",
      "        word = matrix[index]#, branch_index]\n",
      "        dists = np.dot(matrix, word).astype(np.float32)\n",
      "        best = np.argsort(dists)[::-1][:topn + 1]\n",
      "        result = [(index2label[sim], float(dists[sim]), sim) for sim in best if sim != index]\n",
      "        return result[:topn]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_doc_matrix = organizer_model.document_matrix.get_value(borrow=True).reshape(-1, 50 * 7)\n",
      "norm_doc_matrix = (norm_doc_matrix / np.sqrt((norm_doc_matrix ** 2).sum(-1))[..., np.newaxis]).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "norm_model_matrix = organizer_model.model_matrix.get_value(borrow=True)\n",
      "norm_model_matrix = (norm_model_matrix / np.sqrt((norm_model_matrix ** 2).sum(-1))[..., np.newaxis]).astype(np.float32)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "most_similar_word(norm_model_matrix,\n",
      "                  index2word, \n",
      "                  word2index,\n",
      "                  \"2\u03c0\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "[('Exact', 0.5835216641426086, 44372),\n",
        " ('Capitalism', 0.5448542833328247, 22124),\n",
        " ('invulnerable', 0.5293102860450745, 49115),\n",
        " ('Yards', 0.5288931131362915, 40900),\n",
        " ('the', 0.5125910639762878, 0),\n",
        " ('candidates', 0.5077399611473083, 3929),\n",
        " ('Tlingit', 0.507131040096283, 18074),\n",
        " ('Warcraft', 0.5021529197692871, 38176),\n",
        " ('Q4', 0.5014289617538452, 42657),\n",
        " ('cesium', 0.5002008080482483, 49728)]"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "most_similar_doc(norm_doc_matrix,\n",
      "                  index2document,\n",
      "                  document2index,\n",
      "                  \"Turkmenistan.txt\",\n",
      "                  code = [0,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 122,
       "text": [
        "[('Du_Fu.txt', 0.20063205063343048, 2697),\n",
        " ('Military_history_of_the_Soviet_Union.txt', 0.1923905909061432, 4095),\n",
        " ('Star_Trek__The_Original_Series.txt', 0.17725923657417297, 3687),\n",
        " ('Ramesses_II.txt', 0.16453512012958527, 4480),\n",
        " ('Nazi_Germany.txt', 0.16344906389713287, 3362),\n",
        " ('Castra.txt', 0.15977706015110016, 3042),\n",
        " ('Fidel_Castro.txt', 0.15962134301662445, 2285),\n",
        " ('The_Simpsons.txt', 0.1553489863872528, 3893),\n",
        " ('Renormalization.txt', 0.15478645265102386, 718),\n",
        " ('Hurricane_Charley.txt', 0.15380248427391052, 2658)]"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}